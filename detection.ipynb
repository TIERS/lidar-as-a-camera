{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af021c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import detection\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "from collections import Counter\n",
    "from numpy import loadtxt\n",
    "\n",
    "#yaml tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c83d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'yolov5' # 'faster' 'mask' 'yolov5' 'yolox'\n",
    "images_folder = './images/signal_images/'\n",
    "detected_thresh = 0.4\n",
    "dim = (1000,300)\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "COCO_INSTANCE_CATEGORY_NAMES = open(\"coco_names.txt\", \"r\").read().split(\",\")\n",
    "# print(COCO_INSTANCE_CATEGORY_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15dd261",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'faster':\n",
    "    model = detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "elif model_name == 'mask':\n",
    "    model = detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "elif model_name == 'yolov5':\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True, pretrained=True, device='cpu')\n",
    "    model.conf = detected_thresh\n",
    "else:\n",
    "    print(\"No Model Selected!\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8611b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = os.listdir(images_folder)\n",
    "pred = []\n",
    "\n",
    "for i in range(len(data_list)):\n",
    "    img_path = os.path.join(images_folder, data_list[i])\n",
    "    # print(img_path)\n",
    "    image = imread(img_path) \n",
    "    if image.size == 0:\n",
    "        print(\"No Images in the Folder\")\n",
    "        continue\n",
    "    image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    if model_name == 'yolov5':\n",
    "        image1 = image\n",
    "        predictions = model(image1)\n",
    "        predictions.save()\n",
    "        predictions.pandas().xyxy[0]\n",
    "    else:\n",
    "        image1 = image.transpose((2, 0, 1))    \n",
    "        image1 = np.expand_dims(image1, axis=0)\n",
    "        image1 = image1 / 255.0\n",
    "        image1 = torch.FloatTensor(image1)\n",
    "\n",
    "        predictions = model(image1)\n",
    "        boxes = predictions[0]['boxes'].detach()\n",
    "        boxes = boxes.cpu().numpy().astype(np.uint16).tolist()\n",
    "        scores = predictions[0]['scores'].detach().cpu().numpy().tolist()\n",
    "        labels = predictions[0]['labels'].detach().cpu().numpy().tolist()\n",
    "        for label, box, s in zip(labels, boxes, scores):\n",
    "            if s < detected_thresh:\n",
    "                continue\n",
    "            pred.append([i,s,[COCO_INSTANCE_CATEGORY_NAMES[label],box]])\n",
    "            cv2.rectangle(image, (box[0], box[1]), (box[2], box[3] ), color=(0,255,0), thickness=2)\n",
    "            pred_class = COCO_INSTANCE_CATEGORY_NAMES[label]\n",
    "            conf = \"{} %\".format(round(s,2))\n",
    "            cv2.putText(image,pred_class, (box[0]-10, box[1]-20), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,255,0),thickness=1)\n",
    "            cv2.putText(image,conf, (box[0]-10, box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,255,0),thickness=1)\n",
    "        cv2.imwrite('./results/images_detected_{}_{}.png'.format(model_name, i),image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-env",
   "language": "python",
   "name": "cv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
